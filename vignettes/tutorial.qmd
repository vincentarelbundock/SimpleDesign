---
title: "`SimpleDesign` tutorial"
---

```{r}
#| include: false
options(SimpleDesign_print_style = "tinytable")
options(width = 150)
set.seed(48103)
```

## Installation

```r
remotes::install_github("vincentarelbundock/SimpleDesign")
```

## Workflow

The `SimpleDesign` workflow starts by defining two simple functions:

1. `dgp()`:
    - Input: Parameters to control the data generating process (DGP)
    - Output: Data for the model fitting function and true value of the estimand
2. `fit()`: 
    - Input: Data frame generated by `dgp()`
    - Output: Data frame with columns
        - Mandatory: `estimator` and `estimate`
        - Optional: `conf.low`, `conf.high`, `p.value`, etc. 

The `SimpleDesign` workflow ends by calling the `diagnose()` function:

```r
diagnose(dgp, fit)
```

The rest of this vignette shows concrete examples, from simple to complex.

## Simple data generating process

First, we load the package and define a `dgp()` function that encodes a simple data generating process (DGP): A two-arm randomized controlled trial with $N=100$ observations, an outcome $Y$, a random treatment $T$, and a treatment effect of $\theta=0.5$. 

The `dgp()` function must return a data frame when called. That data frame must also have a "truth" attribute, which holds the true value of the estimand that we are targetting.

```{r}
library(SimpleDesign)

dgp = function(theta = 0.5, N = 50) {
  T = rbinom(N, 1, .5) # treatment
  e = rnorm(N) # noise
  Y = theta * T + e # outcome

  # output data frame
  data = data.frame(Y, T)

  # set the "truth" attribute
  attr(data, "truth") = theta
  return(data)
}

dgp() |> head()
```

::: {.callout-important}
Adding the `truth` attribute to the data frame is essential for diagnosis. This attribute must be a numeric vector of length 1 or of length equal to the number of estimates returned by the `fit()` function defined below.
:::

Next, we define a `fit()` function. This function accepts a data frame, fits a model, and returns a data frame of estimates. That data frame must absolutely include an `estimate` column with numeric values. 

```{r}
fit = function(data) {
  model = lm(Y ~ T, data = data)
  results = data.frame(
    estimator = "OLS",
    estimate = coef(model)["T"]
  )
  return(results)
}

dgp() |> fit()
```

Finally, we feed both the `dgp()` and the `fit()` functions to the `diagnose()` function. This function will simulate data from the `dgp()` function, fit models using the `fit()` function, and return a data frame with diagnostic statistics. The `truth` attribute of the generated data specifies the true value of the quantity of interest, against which we benchmark estimates.


```{r}
diagnose(dgp, fit)
```

The `fit()` function can also produce data frames with additional columns like `conf.low`, `conf.high`, and `p.values`. When those columns are present, `diagnose()` will generate more useful diagnostic statistics.

Extracting that information from models is relatively easy, but it is inconvenient. To make this process easier, `SimpleDesign` supplies the `extract_estimates()` function. The optional `term` argument specifies the subset of parameters to extract from the model.

This function works on most model types, and can be used on them directly:

```{r}
mod = lm(mpg ~ hp, data = mtcars) 
extract_estimates(OLS = mod)
```

We use this convenience function to clean-up the output of `fit()`:

```{r}
fit = function(data) {
  results = extract_estimates(
    OLS = lm(Y ~ T, data = data),
    term = "T")
  return(results)
}

dgp() |> fit()
```

Since the `fit()` output now includes the $p$ value and confidence interval, `diagnose()` now reports more useful statistics.

```{r}
diagnose(dgp, fit)
```

## DGP parameters

The `dgp()` function has two arguments to control the sample and effect sizes. We can diagnose several research designs in one go by supplying a data frame of DGP parameters to the `dgp_parameters` argument of `diagnose()`. In this example, we use the `expand.grid()` function from base `R` to build a data frame with all combinations of parameter values.

```{r}
param = expand.grid(N = c(100, 500), theta = c(0.1, 0.5, 1))
param

diagnose(dgp, fit, N = 100, dgp_parameters = param)
```

## Complex data generating process

Since `dgp()` is just a standard `R` function, users are free to define complex data generating processes using whatever helper functions they wish. For example, the `fabricatr` and `randomizr` packages offer extremely powerful functions to generate simulated data with special random assignment schemes. For example, this `dgp()` generates data from a block random assignment design.



```{r}
dgp = function(n_blocks = 3, n_indiv = 100, e_sd = 1) {
  data = fabricatr::fabricate(
    # block-level variables
    block = fabricatr::add_level(
      N = n_blocks,

      # individual treatment effect
      tau = c(4, 2, 0)
    ),

    # individual-level variables
    indiv = fabricatr::add_level(
      N = n_indiv,

      # noise
      e = rnorm(N, sd = e_sd),

      # potential outcomes
      Y_T_0 = e,
      Y_T_1 = e + tau
    )
  )
  data$T = randomizr::block_ra(blocks = data$block, block_prob = c(.5, .7, .9))
  data$Y = ifelse(data$T == 1, data$Y_T_1, data$Y_T_0)

  # define truth in terms of potential outcomes
  attr(data, "truth") = mean(data$Y_T_1 - data$Y_T_0)

  return(data)
}

dgp() |> head()

dgp() |> attr("truth")
```

Now, we define a fit function to see if a "naive" linear regression model retrieves a good estimate of the estimand.

```{r}
fit = function(data) {
  results = extract_estimates(
    OLS = lm(Y ~ T, data = data),
    term = "T")
  return(results)
}
```

Finally, we diagnose the research design.

```{r}
diagnose(dgp, fit)
```

## Comparing estimators

Perhaps we should switch estimators. As described on the [DeclareDesign blog](https://declaredesign.org/blog/posts/biased-fixed-effects.html), we could try to control for blocks fixed effects in the linear model, or estimate differences-in-means in each group and then average them. That last option is implemented by the `differences_in_means()` function from the `estimatr` package.

Again, we use the `extract_estimates()` helper function, which accepts a named list of models, and returns a simple data frame with appropriate labels. To illustrate, let's simulate a single dataset, store three fitted models in a named list, and call `extract_estimates()`. For fun, we also set the $\alpha$ level used to build confidence intervals to 0.01.

```{r}
data = dgp()

extract_estimates(
  `Naive LM` = lm(Y ~ T, data = data),
  `Block controls` = lm(Y ~ T + block, data = data),
  `DinM` = estimatr::difference_in_means(Y ~ T, blocks = block, data = data),
  term = "T",
  alpha = 0.01
)
```

Using this helper function, we can define a new `fit()` and compare different modelling strategies:

```{r}
fit = function(data) {
  results = extract_estimates(
    `Naive LM` = lm(Y ~ T, data = data),
    `Block controls` = lm(Y ~ T + block, data = data),
    `DinM` = estimatr::difference_in_means(Y ~ T, blocks = block, data = data),
    term = "T",
    alpha = 0.01
  )
  return(results)
}
diagnose(dgp, fit)
```

These results show that the difference-in-means strategy yields unbiased results with adequate coverage. We could extend our investigation to consider different DGP parameters:

```{r}
param = expand.grid(n_indiv = c(100, 500), e_sd = c(1, 2))

diagnose(dgp, fit, dgp_parameters = param)
```


## Regression adjustment

```{r}
library(marginaleffects)

dgp = function(N = 100, theta = 0.5) {
  # random treatment
  T = rbinom(N, 1, .5)

  # noise
  epsilon = rnorm(N)

  # coefficients of X1, X2, ...
  beta = runif(5, -1, 1)

  # X is multivariate normal
  sigma = matrix(.5, ncol = 5, nrow = 5)
  diag(sigma) = 1
  mu = rep(1, 5)
  X = MASS::mvrnorm(N, mu, sigma)

  # outcome
  Y = theta * T + X %*% beta + epsilon

  data = data.frame(Y, T, X)

  attr(data, "truth") = theta

  return(data)
}


fit = function(data) {
  unadjusted = lm(Y ~ T, data = data)
  adjusted = lm(Y ~ T * (X1 + X2 + X3 + X4 + X5), data = data)
  adjusted = avg_comparisons(adjusted, variables = "T")
  adjusted = adjusted[, c("term", "estimate", "p.value", "conf.low", "conf.high")]
  results = extract_estimates(
    Unadjusted = unadjusted,
    Adjusted = adjusted,
    term = "T"
  )
  return(results)
}

diagnose(dgp, fit)
```


